{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 118B - Project Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "- Brinda Narayanan\n",
    "- Leena Jannatipour\n",
    "- Eric Lin\n",
    "- Bryan Nguyen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract \n",
    "This project is to identify clusters of apples based on their different attributes through unsupervised machine learning. The dataset is sourced from Kaggle, and contains 4000 observations with 8 variables each (size, weight, sweetness, crunchiness, juiciness, ripeness, quality, and acidity). We will be ignoring the true quality label to see if natural quality groupings form. We will be using K-means clustering and GMM to identify the clusters, and we will be comparing the unsupervised results with a baseline of random clustering. We will be using the Silhouette score to measure the similarity of an apple to its cluster. The overall goal of this project is to see how effective unsupervised learning is when applied to agricultural datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "In a highly competitive fruit market, apples have become a common item in a household’s grocery list. Thus, making the quality that is put out important among farmers, distributors, etc. High-quality apples command premium prices in the market. Producers and retailers can achieve higher profit margins by offering top-quality apples that meet consumer expectations and demand<a name=\"mediumnote\"></a>[<sup>[1]</sup>](#mediumnote). \n",
    "\n",
    "Using machine learning in apple quality is relatively new, but is something that shows potential, especially in image data. Previous work to cluster apples into their own categories has been done with K-means clustering<a name=\"sciencedirectnote\"></a>[<sup>[2]</sup>](#sciencedirectnote). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "Objective: Utilize unsupervised learning techniques to identify distinct clusters of apples based on their physical attributes (size, color, weight, etc.) without the true quality label. We will be uncovering natural groupings that correspond to different quality levels and suitability for specific market segments.\n",
    "\n",
    "\n",
    "With this problem solved, grocery fruit life can be quantified when apple quality is set in standard. Harvest and storage conditions can also be accurately measured and recorded. The model predictions can be compared against observed outcomes. This model can be replicated to different seasons and regions, making the problem and solution widely applicable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "- link: https://www.kaggle.com/datasets/nelgiriyewithana/apple-quality/data\n",
    "- 8 variables, 4000 observations\n",
    "- An observation consists of size, weight, sweetness, crunchiness, juiciness, ripeness, acidity, and quality. \n",
    "- We presume the critical variables will be size, weight, sweetness, and acidity, which are all represented by a number scale which appears to be a normal distribution centered at 0.\n",
    "- It does not appear that there is much need for cleaning in this data; all the data with the exception of “quality” is represented by a normal distribution number scale centered at 0. We may remove the quality column in order to check to see if the model separates different qualities of fruit without the variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Solution\n",
    "\n",
    "In order to identify distinct clusters of apples that correspond to their physical attributes (size, weight, sweetness, acidity), we will be employing two different clustering methods for this unsupervised learning problem: K-Means Clustering and Gaussian Mixture Model Clustering. As a baseline model, we will employ random clustering to measure the effectiveness of our chosen clustering methods.\n",
    "The first method will be K-Means Clustering, this will create clusters based on each data observation’s proximity to the nearest mean. To determine the amount of clusters (k) to use, we will use the elbow method to find the optimal number of clusters for this dataset. The elbow method calculates the optimal amount of clusters to use by employing K-Means clustering for different cluster (k) values, then plotting the mean distance to the centroid for each k and choosing the k value where the rate of decrease shifts or where you notice an elbow-like curve in the plot.\n",
    "\n",
    "Pseudocode for elbow-curve method to choose k clusters: <a name=\"sota\"></a>[<sup>[3]</sup>](#banerjinote)\n",
    "$\n",
    "\\text{dist = []}\\newline\n",
    "\\text{K = {1,10}}\\newline\n",
    "\\text{For cluster_num in K:}\\newline\n",
    "\t\\text{kmeans = KMeans(cluster_num)}\\newline\n",
    "\t\\text{kmeans.fit(df)}\\newline\n",
    "\t\\text{dist.append(kmeans.inertia)}\\newline\n",
    "\\text{plt.plot(K, dist)}\\newline\n",
    "\\text{plt.xlabel(“K Values”)}\\newline\n",
    "\\text{plt.ylabel(“Sum of Squared Distances/Inertia”)}\\newline\n",
    "\\text{plt.title(“Elbow Method to choose an optimal K”)}\\newline\n",
    "\\text{plt.show()}\n",
    "$\n",
    "\n",
    "Pseudocode for K-Means Clustering Algorithm:\n",
    "1) Use optimal number of clusters calculated with elbow curve method $\\newline$\n",
    "2) Initialize k centroids randomly $\\newline$\n",
    "3) Assign each data observation to its nearest centroid $\\newline$\n",
    "4) Compute mean of all data points in a cluster, k, and update the centroid values $\\newline$\n",
    "5) Repeat until convergence\n",
    "\t\n",
    "The second method we will employ will be GMM Clustering, this will allow for each data observation to have a probability of belonging to a cluster via its likelihood (fuzzy clustering).\n",
    "\n",
    "Pseudocode for GMM Clustering Algorithm:\n",
    "1) Choose optimal number of clusters (Bayesian information criterion) $\\newline$\n",
    "2) Generate gaussian model for each cluster $\\newline$\n",
    "3) For each data point, calculate probability of belonging to a cluster $\\newline$\n",
    "4) Use above probabilities to recalculate the gaussian model for each cluster (weighted observations)$\\newline$\n",
    "5) Repeat until the observations converge on their assigned cluster (EM algorithm)\n",
    "\n",
    "To test this solution, we will separate the data into a training set and a testing set and apply both clustering methods onto the training set. Using the clustering performance seen in the training set, we will assess our method’s performance onto the testing set and validate reproducibility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "One evaluation metric we plan to use to quantify the performance of both our baseline and solution model will be the Silhouette Score. This will allow us to measure the similarity of an apple to its cluster and then compared to other clusters. On a scale from -1 to 1, a high silhouette score indicates a good-fit to its own cluster and poorly matched to other clusters.\n",
    "$$\n",
    "s_i = \\frac{b_i - a_i}{max(b_i, a_i)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "b_i = \\text{average distance to closest cluster of datapoint i}\n",
    "$$\n",
    "\n",
    "$$\n",
    "b_i = min_{k \\neq 1} \\frac{1}{|C_k|} \\sum_{j \\in C_k} d(i,j)\n",
    "$$\n",
    "\n",
    "$$\n",
    "a_i = \\text{average distance to all other points in the cluster}\n",
    "$$\n",
    "\n",
    "$$\n",
    "a_i = \\frac{1}{|C_i| - 1} \\sum_{j \\in C_i, i \\neq j} d(i,j)\n",
    "$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I do not believe there are any concerns regarding ethics or data privacy here. The dataset that is being used is publicly available on Kaggle, and the information that is being analyzed is in regards to fruit, which is not personal information. Potentially, this information could have some issues regarding subjectivity when it comes to what constitutes ripeness, crunchiness, sweetness, etc. This could create some kind of bias in the dataset. Unfortunately, as we do not know exactly how this data was collected, there is not much we can do to mitigate this bias. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Expectations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *We will be communicating through discord, communication is key so if there are any conflicts we will talk it out or put it on campaswire/ go to OH to ask for advice.*\n",
    "* *We expect everyone to equally do their part: Brinda, Yiling, Leena: Coding Clustering Algorithms, Eric & Prom: Helping analyze algorithms*\n",
    "* *We have set our goals and schedule in the proposal below, and expect to stick by it.*\n",
    "* *Deadlines: we will meet the day before any deadline to make sure all parts are done well.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Timeline Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace this with something meaningful that is appropriate for your needs. It doesn't have to be something that fits this format.  It doesn't have to be set in stone... \"no battle plan survives contact with the enemy\". But you need a battle plan nonetheless, and you need to keep it updated so you understand what you are trying to accomplish, who's responsible for what, and what the expected due dates are for each item.\n",
    "\n",
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 2/19  |  12 PM |  Brainstorm datasets& unsupervised ML methods  | Determine best form of communication; Discuss and decide on final project topic and Dataset; discuss hypothesis; begin background research | \n",
    "| 2/26  |  12 PM |  Do background research on clustering for quality items (Brinda) |EDA on the dataset, start discussing ways to wrangle, split wrangling and cleaning duties if needed. | \n",
    "| 3/4  | 12 PM  | Finalize wrangling/EDA; Begin programming for project (Entire Team) | Assign group members to lead each specific part |\n",
    "| 3/11  | 12 PM  | Coders do their sections and have it done so writers can write it out | Discuss/edit project code; Complete coding sections   |\n",
    "| 3/18  | 12 PM  | Submit Project before 10pm | Last minute changes and one final read through |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "<a name=\"mediumnote\"></a>1.[^](#mediumnote): (6 Feb 2024) The Science behind growing high-quality apples *Medium* https://medium.com/@leafylives.in/the-science-behind-growing-high-quality-apples-163f9dad98e2 <br> \n",
    "\n",
    "<a name=\"sciencedirectnote\"></a>2.[^](#sciencedirectnote): (16 Dec 2020) Automatic grading of apples based on multi-features and weighted K-means clustering algorithm *Science Direct* https://www.sciencedirect.com/science/article/pii/S2214317319300794 <br>\n",
    "\n",
    "<a name=\"banerjinote\"></a>3.[^](#sota): Banerji, Ankita (3 Aug 2023) K-Mean: Getting the Optimal Number of Clusters *Analytics Vidhya*. https://www.analyticsvidhya.com/blog/2021/05/k-mean-getting-the-optimal-number-of-clusters/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
